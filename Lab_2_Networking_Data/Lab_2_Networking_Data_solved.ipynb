{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Networking Data\n",
    "\n",
    "What we will do:\n",
    "\n",
    "1. Create an edge list for a mention and a hashtag network based on the data collected in Lab 1\n",
    "2. Exploratively analyse both networks in Gephi\n",
    "\n",
    "Again, there will be two versions of this so called Jupyter Notebook for you to follow along:\n",
    "\n",
    "* One already filled out for you, in case you want to pay more attention on other things than typing or rather alter the code to try new things.\n",
    "* Another one with the code 'cells' emptied for you to practice your Python typing skills alongside the lecturer (or maybe sometimes find even better solutions to the given problems)\n",
    "\n",
    "Secret tip: If you want to try this at home, Github Copilot (free for students), ChatGPT and Bing Chat got pretty good at generating code for you. However, you still should be able to make sure that the code they produced actually does what you want it to do. So you still have to learn some Python.\n",
    "\n",
    "But now let's start."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data\n",
    "\n",
    "Make sure you still have or have uploaded the `leo_tweets.csv` file into the root folder of this notebook. If you have not done so, please do so. You were asked to download it last time. If you have lost it, ask the lecturer for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(\"../leo_tweets.csv\")\n",
    "\n",
    "# show the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the columns of the dataset\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mention Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create a so called edge list for a mention network. This means one column contains the accounts mentioning other accounts and the other column contains the accounts being mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataset to possibly relevant columns\n",
    "mentions = df[[\"user_screen_name\", \"to_username\", \"text\", \"mentioned_names\"]]\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect rows where the to_username is not null\n",
    "mentions[mentions[\"to_username\"].notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect rows where the mentioned_names is not null\n",
    "mentions[mentions[\"mentioned_names\"].notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mentioned_names seems to be the relevant column\n",
    "# It is a list of users mentioned in the tweet\n",
    "# Let's filter the dataset to only include rows where mentioned_names is not null\n",
    "mentions = mentions[mentions[\"mentioned_names\"].notnull()]\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to split the mentioned_names column into multiple rows\n",
    "# We can do this by using the split and explode function\n",
    "# First we split the mentioned_names column by the pipe character\n",
    "mentions[\"mentioned_names\"] = mentions[\"mentioned_names\"].str.split(\"|\")\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we explode the mentioned_names column\n",
    "mentions = mentions.explode(\"mentioned_names\")\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by now we can remove the to_username and text columns\n",
    "mentions = mentions[[\"user_screen_name\", \"mentioned_names\"]]\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there duplicate rows?\n",
    "mentions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means we  have to take care of weights later on\n",
    "# Let's rename the columns ot Source and Target and export to a csv file for Gephi\n",
    "mentions.columns = [\"Source\", \"Target\"]\n",
    "mentions.to_csv(\"mentions.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hashtag Co-Use Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to create a network of hashtags\n",
    "# Whenever two hashtags appear in the same tweet, we want to create an edge between them\n",
    "# Let's start by looking at the possibly relevant columns again\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'hashtags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets filter the dataset to only include rows where hashtags is not null and keep only the relevant column\n",
    "hashtags = df[df[\"hashtags\"].notnull()][[\"hashtags\"]]\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal is to have one row for every pair of hashtags in hashtags\n",
    "# First we split the hashtags column by the pipe character again\n",
    "hashtags[\"hashtags\"] = hashtags[\"hashtags\"].str.split(\"|\")\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to find all possible combinations of hashtags with the itertools package\n",
    "import itertools\n",
    "\n",
    "hashtags['hashtag_pairs'] = hashtags['hashtags'].apply(lambda x: list(itertools.combinations(x, 2)))\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can explode the hashtag_pairs column\n",
    "hashtags = hashtags.explode(\"hashtag_pairs\")\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can remove the hashtags column and split the hashtag_pairs column into two columns\n",
    "hashtags = hashtags[\"hashtag_pairs\"]\n",
    "hashtags = hashtags.apply(pd.Series) # split the column into two columns (unintuitive, but it works)\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's rename the columns to Source and Target and export to a csv file for Gephi\n",
    "hashtags.columns = [\"Source\", \"Target\"]\n",
    "hashtags.to_csv(\"hashtags.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fundamentals_of_Online__Social__Network_An-_5iAiouA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
